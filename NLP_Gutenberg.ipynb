{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9cc8c8a-9b15-45ab-999b-d61591e70f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9e289-0d5a-4eec-9119-10ac96014e99",
   "metadata": {},
   "source": [
    "This is an NLP project that aims to create new text based on patterns in any body of text entered. It works using a series of conditional probabilities computed from an 'N-gram' division of words, and then produces a sample of text based on this model. It also includes a webscraping component, since I got my text data from the project gutenberg website. Below is an example of this model being using on the book beowulf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b57a4c9-e6e8-4dc0-9fa9-a137dd17a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book(url):\n",
    "    time.sleep(7)\n",
    "    text = str(requests.get(url).text).replace(\"\\r\\n\", \"\\n\")\n",
    "    first = text.find(\"***\")\n",
    "    text = text[first+ 4:]\n",
    "    second = text[3:].find(\"***\")\n",
    "    text = text[second + 6:]\n",
    "    return text[:text.find(\"***\")]\n",
    "\n",
    "\n",
    "text = str(requests.get('https://www.gutenberg.org/files/57988/57988-0.txt').text).replace(\"\\r\\n\", \"\\n\")\n",
    "first = text.find(\"***\")\n",
    "text = text[first+ 4:]\n",
    "second = text[3:].find(\"***\")\n",
    "#end = text[second + 6:].find(\"END\")\n",
    "\n",
    "text = text[second + 6:]\n",
    "#text[:text.find(\"***\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "188b66f1-cd28-4b15-a128-c94c88509136",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note \\xo2 indicates the start of a sentence and xo3 indicates the end of one.\n",
    "def tokenize(book_string):\n",
    "    works = book_string\n",
    "    works = re.sub(\"^\\n+\", \" \\x02 \", works)\n",
    "    works = re.sub(\"\\n+$\", \" \\x03\", works)\n",
    "    works = re.sub(\"(\\n\\n)+\", ' \\x03 \\x02 ', works)\n",
    "    works = works.replace(\"\\n\", \" \")\n",
    "    for i in '''!()-[]{};:'\"\\,â€™<>./?@#$%^&*_~''':\n",
    "        works = works.replace(i, \" \" + i + \" \")\n",
    "    works = works.replace(\"...\", \" ... \")\n",
    "    \n",
    "    works = re.sub(\" +\", \" \", works).split(\" \")\n",
    "    if \"\" in works:\n",
    "        works.remove(\"\")\n",
    "    if works[0] != \"\\x02\":\n",
    "        works = [\"\\x02\"] + works\n",
    "    if works[-1] != \"\\x03\":\n",
    "        works = works + [\"\\x03\"]\n",
    "    return works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f420f01d-3a34-4478-b3d3-5ee3bf8f4376",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnigramLM(object):\n",
    "    \n",
    "    def __init__(self, tokens):\n",
    "        \"\"\"\n",
    "        Initializes a Unigram languange model using a\n",
    "        list of tokens. It trains the language model\n",
    "        using `train` and saves it to an attribute\n",
    "        self.mdl.\n",
    "        \"\"\"\n",
    "        self.mdl = self.train(tokens)\n",
    "    \n",
    "    def train(self, tokens):\n",
    "        \"\"\"\n",
    "        Trains a unigram language model given a list of tokens.\n",
    "        The output is a series indexed on distinct tokens, and\n",
    "        values giving the probability of a token occuring\n",
    "        in the language.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unig = UnigramLM(tokens)\n",
    "        >>> isinstance(unig.mdl, pd.Series)\n",
    "        True\n",
    "        >>> set(unig.mdl.index) == set('one two three four'.split())\n",
    "        True\n",
    "        >>> unig.mdl.loc['one'] == 3 / 7\n",
    "        True\n",
    "        \"\"\"\n",
    "        df = pd.DataFrame(data = pd.Series(tokens), columns = [\"words\"])\n",
    "        df[\"count\"] = np.full(len(tokens), 1)\n",
    "        count = df.groupby(\"words\").count()[\"count\"]\n",
    "        count = count/count.sum()\n",
    "        return count\n",
    "    \n",
    "    def probability(self, words):\n",
    "        \"\"\"\n",
    "        probability gives the probabiliy a sequence of words\n",
    "        appears under the language model.\n",
    "        :param: words: a tuple of tokens\n",
    "        :returns: the probability `words` appears under the language\n",
    "        model.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unig = UnigramLM(tokens)\n",
    "        >>> unig.probability(('five',))\n",
    "        0\n",
    "        >>> p = unig.probability(('one', 'two'))\n",
    "        >>> np.isclose(p, 0.12244897959, atol=0.0001)\n",
    "        True\n",
    "        \"\"\" \n",
    "        \n",
    "        try:\n",
    "            prob = np.prod(self.mdl.loc[list(words)])\n",
    "        except:\n",
    "            prob = 0\n",
    "        return prob\n",
    "        \n",
    "    def sample(self, M):\n",
    "        \"\"\"\n",
    "        sample selects tokens from the language model of length M, returning\n",
    "        a string of tokens.\n",
    "\n",
    "        >>> tokens = tuple('one one two three one two four'.split())\n",
    "        >>> unig = UnigramLM(tokens)\n",
    "        >>> samp = unig.sample(1000)\n",
    "        >>> isinstance(samp, str)\n",
    "        True\n",
    "        >>> len(samp.split()) == 1000\n",
    "        True\n",
    "        >>> s = pd.Series(samp.split()).value_counts(normalize=True).loc['one']\n",
    "        >>> np.isclose(s, 0.41, atol=0.05).all()\n",
    "        True\n",
    "        \"\"\"\n",
    "        return \" \".join(list(np.random.choice(list(self.mdl.index), M, p = list(self.mdl.values))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb8b0933-e88d-4078-8d4e-398235e27572",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramLM(object):\n",
    "    \n",
    "    def __init__(self, N, tokens):\n",
    "        \"\"\"\n",
    "        Initializes a N-gram languange model using a\n",
    "        list of tokens. It trains the language model\n",
    "        using `train` and saves it to an attribute\n",
    "        self.mdl.\n",
    "        \"\"\"\n",
    "        # You don't need to edit the constructor,\n",
    "        # but you should understand how it works!\n",
    "        \n",
    "        self.N = N\n",
    "\n",
    "        ngrams = self.create_ngrams(tokens)\n",
    "\n",
    "        self.ngrams = ngrams\n",
    "        self.mdl = self.train(ngrams)\n",
    "\n",
    "        if N < 2:\n",
    "            raise Exception('N must be greater than 1')\n",
    "        elif N == 2:\n",
    "            self.prev_mdl = UnigramLM(tokens)\n",
    "        else:\n",
    "            self.prev_mdl = NGramLM(N-1, tokens)\n",
    "\n",
    "    def create_ngrams(self, tokens):\n",
    "        \"\"\"\n",
    "        create_ngrams takes in a list of tokens and returns a list of N-grams. \n",
    "        The START/STOP tokens in the N-grams should be handled as \n",
    "        explained in the notebook.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('\\x02 one two three one four \\x03'.split())\n",
    "        >>> bigrams = NGramLM(2, [])\n",
    "        >>> out = bigrams.create_ngrams(tokens)\n",
    "        >>> isinstance(out[0], tuple)\n",
    "        True\n",
    "        >>> out[0]\n",
    "        ('\\\\x02', 'one')\n",
    "        >>> out[2]\n",
    "        ('two', 'three')\n",
    "        \"\"\"\n",
    "        temp = zip(*[tokens[i:] for i in range(0,self.N)])\n",
    "        lis = []\n",
    "        for i in temp:\n",
    "            lis.append((i))\n",
    "        return lis\n",
    "        \n",
    "    def train(self, ngrams):\n",
    "        \"\"\"\n",
    "        Trains a n-gram language model given a list of tokens.\n",
    "        The output is a dataframe with three columns (ngram, n1gram, prob).\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('\\x02 one two three one four \\x03'.split())\n",
    "        >>> bigrams = NGramLM(2, tokens)\n",
    "        >>> set(bigrams.mdl.columns) == set('ngram n1gram prob'.split())\n",
    "        True\n",
    "        >>> bigrams.mdl.shape == (6, 3)\n",
    "        True\n",
    "        >>> bigrams.mdl['prob'].min() == 0.5\n",
    "        True\n",
    "        \"\"\"\n",
    "        if len(ngrams) == 0:\n",
    "            return []\n",
    "        df = pd.DataFrame()\n",
    "        df[\"ngram\"] = ngrams\n",
    "        df[\"second\"] = pd.Series(ngrams).str[0:len(ngrams[0]) - 1]\n",
    "        df.columns = [\"ngram\",\"n1gram\"]\n",
    "\n",
    "\n",
    "\n",
    "        col1 = df.groupby(\"ngram\")[\"n1gram\"].transform('count')\n",
    "        col2 = df.groupby(\"n1gram\")[\"ngram\"].transform('count')\n",
    "        df[\"prob\"] = col1/col2\n",
    "        return df.drop_duplicates()\n",
    "\n",
    "        \n",
    "    \n",
    "    def probability(self, words):\n",
    "        \"\"\"\n",
    "        probability gives the probabiliy a sequence of words\n",
    "        appears under the language model.\n",
    "        :param: words: a tuple of tokens\n",
    "        :returns: the probability `words` appears under the language\n",
    "        model.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('\\x02 one two one three one two \\x03'.split())\n",
    "        >>> bigrams = NGramLM(2, tokens)\n",
    "        >>> p = bigrams.probability('two one three'.split())\n",
    "        >>> np.isclose(p, (1/4) * (1/2) * (1/3))\n",
    "        True\n",
    "        >>> bigrams.probability('one two five'.split()) == 0\n",
    "        True\n",
    "        \"\"\"\n",
    "        try:\n",
    "            lat_len = len(words) - (self.N - 1)\n",
    "            ser = self.mdl.set_index('ngram').loc[self.create_ngrams(words)]['prob']\n",
    "            latter = np.prod(ser.groupby(ser.index).first())\n",
    "        except:\n",
    "            return 0\n",
    "        \n",
    "\n",
    "        previous = self.prev_mdl\n",
    "        while isinstance(previous.mdl, pd.DataFrame):\n",
    "            latter = latter * previous.mdl.set_index(\"ngram\").loc[[tuple(words[0:previous.N])]][\"prob\"][0]\n",
    "            previous = previous.prev_mdl\n",
    "        latter2 = latter * previous.mdl.loc[words[0]]\n",
    "        return latter2\n",
    "    \n",
    "\n",
    "    def sample(self, M):\n",
    "        \"\"\"\n",
    "        sample selects tokens from the language model of length M, returning\n",
    "        a string of tokens.\n",
    "\n",
    "        :Example:\n",
    "        >>> tokens = tuple('\\x02 one two three one four \\x03'.split())\n",
    "        >>> bigrams = NGramLM(2, tokens)\n",
    "        >>> samp = bigrams.sample(3)\n",
    "        >>> len(samp.split()) == 4  # don't count the initial START token.\n",
    "        True\n",
    "        >>> samp[:2] == '\\\\x02 '\n",
    "        True\n",
    "        >>> set(samp.split()) <= {'\\\\x02', '\\\\x03', 'one', 'two', 'three', 'four'}\n",
    "        True\n",
    "        \"\"\"\n",
    "        grass_model = self\n",
    "        prev_model = self\n",
    "        string = \"\\x02\"\n",
    "        # Use a helper function to generate sample tokens of length `length`\n",
    "        if grass_model.N == 2:\n",
    "            first_prob = prev_model.mdl[pd.Series(prev_model.mdl[\"ngram\"]).str[0] == \"\\x02\"]\n",
    "            ans = first_prob.drop_duplicates()\n",
    "            next_words = np.random.choice(ans[\"ngram\"], 1, p = ans[\"prob\"])\n",
    "            next_word = next_words[0][1]\n",
    "            string = string + \" \"+ next_word\n",
    "            for i in range(M-2):\n",
    "                x = grass_model.mdl[pd.Series(prev_model.mdl[\"ngram\"]).str[0:1] == (next_words[0][1],)]\n",
    "                ans = x.drop_duplicates()\n",
    "                next_words = [np.random.choice(ans[\"ngram\"], 1, p = ans[\"prob\"])[0][0:]]\n",
    "                next_word = next_words[0][1]\n",
    "                string = string + \" \"+ next_word\n",
    "            return string + \" \\x03\"\n",
    "        else:\n",
    "            \n",
    "        # Transform the tokens to strings\n",
    "            while prev_model.N != 2:\n",
    "                prev_model = prev_model.prev_mdl\n",
    "            first_prob = prev_model.mdl[pd.Series(prev_model.mdl[\"ngram\"]).str[0] == \"\\x02\"]\n",
    "            ans = first_prob.drop_duplicates()\n",
    "            next_words = np.random.choice(ans[\"ngram\"], 1, p = ans[\"prob\"])\n",
    "            next_word = next_words[0][1]\n",
    "            string = string + \" \"+ next_word\n",
    "\n",
    "            for i in range(3,self.N):\n",
    "                prev_model = self\n",
    "                for j in range(self.N - i):\n",
    "                    prev_model = prev_model.prev_mdl\n",
    "                x = prev_model.mdl[pd.Series(prev_model.mdl[\"ngram\"]).str[0:i-1] == next_words[0]]\n",
    "                ans = x.drop_duplicates()\n",
    "                next_words = [np.random.choice(ans[\"ngram\"], 1, p = ans[\"prob\"])[0][0:]]\n",
    "                #print(next_words)\n",
    "                next_word = next_words[0][i-1]\n",
    "                string = string + \" \"+ next_word\n",
    "            num_left = (M - (self.N - 1))\n",
    "            for i in range(num_left):\n",
    "                try:\n",
    "                    x = self.mdl[pd.Series(self.mdl[\"ngram\"]).str[0:len(next_words[0])] == next_words[0]]\n",
    "                    ans = x.drop_duplicates()\n",
    "                    next_words = [np.random.choice(ans[\"ngram\"], 1, p = ans[\"prob\"])[0][1:]]\n",
    "                    next_word = next_words[0][-1]\n",
    "                    string = string + \" \"+ next_word\n",
    "                except:\n",
    "                    string = string + \" \" + \"\\x03\"\n",
    "\n",
    "            string = string + \" \\x03\"\n",
    "            return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0eeeedcb-15f1-4889-98dc-4c4228f06762",
   "metadata": {},
   "outputs": [],
   "source": [
    "beowulf = get_book('https://www.gutenberg.org/ebooks/16328.txt.utf-8')\n",
    "beo_tokens = tokenize(beowulf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "625a3d52-6de7-4a50-baff-5a352455235c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beo = NGramLM(5, beo_tokens )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7916a8eb-22e0-4dc9-817a-16ea36647e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x02 _ When the hero arrives in his own land , Higelac treats him as a distinguished guest . He is the great - grandfather of Hrothgar , so prominent in the poem . } \\x03 \\x02 It pains me in spirit to any to tell it , What grief in Heorot Grendel hath caused me , 20 What horror unlooked - for , by hatred unceasing . Waned is my war - band , purify Heorot . I have heard on inquiry , Outstruck in its stroke , when to struggle he carried The wonderful war - sword : \\x03'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beo.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdfe571-e1ab-46d0-bfd8-c377926a5da5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
